1. fast api to qwen-vl-int4.ipynb from main.py



example of code for base4 decoding:
----------------------------------------------------------------

import base64
imgdata = base64.b64decode(imgstring)
filename = 'some_image.jpg'  # I assume you have a way of picking unique filenames
with open(filename, 'wb') as f:
    f.write(imgdata)
# f gets closed when you exit the with statement
# Now save the value of filename to your database

-------------example2 of base64 decoding------------------------

from PIL import Image
import base64
import io

def base64_to_jpg(base64_str, output_path="output.jpg"):
    if base64_str.startswith("data:image"):
        base64_str = base64_str.split(",", 1)[1]
    
    img = Image.open(io.BytesIO(base64.b64decode(base64_str)))
    if img.mode != "RGB":
        img = img.convert("RGB")
    
    img.save(output_path, "JPEG", quality=95)
    return output_path

----------------------------------------------------------------




example of fast api of qwen-vl-int4.ipynb:
----------------------------------------------------------------

from fastapi import FastAPI, UploadFile, HTTPException
from fastapi.responses import JSONResponse
from PIL import Image
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import tempfile
import os

app = FastAPI()

@app.on_event("startup")
async def load_model():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    try:
        app.state.tokenizer = AutoTokenizer.from_pretrained(
            "Qwen/Qwen-VL-Chat-Int4", 
            trust_remote_code=True
        )
        app.state.model = AutoModelForCausalLM.from_pretrained(
            "Qwen/Qwen-VL-Chat-Int4",
            device_map=device,
            trust_remote_code=True
        ).eval()
    except Exception as e:
        raise RuntimeError(f"Model loading failed: {str(e)}")

PROMPT_TEMPLATE = (
    "Describe what you see in the photo. Speak like with a person from 8 to 14 years old. "
    "Speak only English. In math tasks, 'x' is a mathematical variable, not multiplication. "
    "Example: for 6x + 5 = 23, it's 6x = 23-5 → 6x = 18 → x = 3"
)

@app.post("/describe/")
async def describe_image(image: UploadFile):
    if not image.content_type.startswith('image/'):
        raise HTTPException(
            status_code=400, 
            detail="Invalid file format. Please upload an image."
        )
    
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(image.filename)[1]) as tmp:
            tmp.write(await image.read())
            tmp_path = tmp.name
        
        img = Image.open(tmp_path)
        if img.mode != "RGB":
            img = img.convert("RGB")
        img.save(tmp_path)
        
        query = app.state.tokenizer.from_list_format([
            {'image': tmp_path},
            {'text': PROMPT_TEMPLATE},
        ])
        
        with torch.no_grad():
            response, _ = app.state.model.chat(
                tokenizer=app.state.tokenizer,
                query=query,
                history=None
            )
        
        os.unlink(tmp_path)
        
        return JSONResponse(content={
            "description": response,
            "original_filename": image.filename,
            "content_type": image.content_type
        })
    
    except Exception as e:
        if 'tmp_path' in locals() and os.path.exists(tmp_path):
            os.unlink(tmp_path)
        raise HTTPException(
            status_code=500, 
            detail=f"Processing error: {str(e)}"
        )

@app.get("/health")
async def health_check():
    return {"status": "ok", "model_loaded": hasattr(app.state, "model")}

----------------------------------------------------------------